{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae95606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f3c76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentic2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd7e631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a95342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking And Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47124a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000021B60CD92D0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000021B60DD53D0> root_client=<openai.OpenAI object at 0x0000021B5F9061D0> root_async_client=<openai.AsyncOpenAI object at 0x0000021B60DD5090> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"o1-mini\")\n",
    "print(llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ca146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Agentic AI** refers to artificial intelligence systems designed to operate as autonomous agents capable of perceiving their environment, making decisions, and taking actions to achieve specific goals without continuous human intervention. The term \"agentic\" emphasizes the AI\\'s ability to act independently, exhibiting behaviors typically associated with agency, such as planning, learning, and adapting to new situations.\\n\\n### Key Characteristics of Agentic AI\\n\\n1. **Autonomy:** Agentic AI operates independently, making decisions without needing explicit instructions for every action. It can set its own objectives based on predefined parameters or learned preferences.\\n\\n2. **Perception:** These AI systems can interpret and understand data from various sources, such as sensors, cameras, or natural language inputs, to assess their environment.\\n\\n3. **Decision-Making:** Agentic AI employs algorithms and models (including machine learning and reinforcement learning) to analyze information, evaluate options, and choose the most appropriate actions to achieve its goals.\\n\\n4. **Adaptability:** Such AI can learn from experiences, adjust to new information, and modify its behavior in response to changing environments or objectives.\\n\\n5. **Goal-Oriented Behavior:** Agentic AI is focused on achieving specific outcomes, whether they are set by users, predefined by developers, or evolved through learning processes.\\n\\n### Applications of Agentic AI\\n\\n- **Autonomous Vehicles:** Self-driving cars that navigate roads, respond to traffic conditions, and make real-time decisions to ensure safe transportation.\\n  \\n- **Robotics:** Robots in manufacturing, healthcare, or service industries that perform tasks autonomously, such as assembly, surgery, or customer assistance.\\n\\n- **Virtual Assistants:** Advanced personal assistants like AI-driven chatbots that manage schedules, perform tasks, and interact with users proactively.\\n\\n- **Autonomous Trading Systems:** AI systems in finance that execute trades based on market analysis and predefined investment strategies without human intervention.\\n\\n- **Smart Homes:** Systems that automatically adjust lighting, temperature, security, and other home functions based on occupant behavior and preferences.\\n\\n### Benefits of Agentic AI\\n\\n- **Efficiency:** Automates repetitive or complex tasks, freeing humans to focus on more strategic activities.\\n  \\n- **Consistency:** Reduces human error by performing tasks with high precision and reliability.\\n\\n- **Scalability:** Can handle large volumes of data and processes that would be challenging for humans to manage effectively.\\n\\n- **Adaptability:** Learns and evolves with changing conditions, enhancing its performance over time.\\n\\n### Challenges and Considerations\\n\\n- **Ethics and Accountability:** Determining responsibility for the actions of autonomous agents, especially in critical applications like healthcare or transportation.\\n\\n- **Safety and Security:** Ensuring that agentic AI systems operate safely and are protected against malicious attacks or unintended behaviors.\\n\\n- **Transparency:** Making the decision-making processes of AI understandable to users and stakeholders to build trust and facilitate oversight.\\n\\n- **Control and Alignment:** Aligning the goals and behaviors of AI agents with human values and intentions to prevent adverse outcomes.\\n\\n### Future Outlook\\n\\nAgentic AI continues to advance, driven by improvements in machine learning, data processing, and computational power. As these systems become more sophisticated, they hold the potential to revolutionize various industries by enabling more intelligent, responsive, and efficient operations. However, it also necessitates ongoing dialogue and collaboration among technologists, policymakers, ethicists, and the public to address the accompanying ethical, social, and legal challenges.\\n\\n---\\n\\nIn summary, **Agentic AI** represents a paradigm of artificial intelligence that emphasizes autonomy and proactive behavior, enabling systems to act as independent agents capable of achieving defined objectives through perception, decision-making, and action.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 861, 'prompt_tokens': 13, 'total_tokens': 874, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_3da8b0b088', 'id': 'chatcmpl-BffiOC82EI2wtB4vYSHQxuoi6WzfA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--a1282122-a19d-426a-9e34-df56a875bd74-0' usage_metadata={'input_tokens': 13, 'output_tokens': 861, 'total_tokens': 874, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}}\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"What is Agentic AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d6b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Agentic AI** refers to artificial intelligence systems designed to operate as autonomous agents capable of perceiving their environment, making decisions, and taking actions to achieve specific goals without continuous human intervention. The term \"agentic\" emphasizes the AI's ability to act independently, exhibiting behaviors typically associated with agency, such as planning, learning, and adapting to new situations.\n",
      "\n",
      "### Key Characteristics of Agentic AI\n",
      "\n",
      "1. **Autonomy:** Agentic AI operates independently, making decisions without needing explicit instructions for every action. It can set its own objectives based on predefined parameters or learned preferences.\n",
      "\n",
      "2. **Perception:** These AI systems can interpret and understand data from various sources, such as sensors, cameras, or natural language inputs, to assess their environment.\n",
      "\n",
      "3. **Decision-Making:** Agentic AI employs algorithms and models (including machine learning and reinforcement learning) to analyze information, evaluate options, and choose the most appropriate actions to achieve its goals.\n",
      "\n",
      "4. **Adaptability:** Such AI can learn from experiences, adjust to new information, and modify its behavior in response to changing environments or objectives.\n",
      "\n",
      "5. **Goal-Oriented Behavior:** Agentic AI is focused on achieving specific outcomes, whether they are set by users, predefined by developers, or evolved through learning processes.\n",
      "\n",
      "### Applications of Agentic AI\n",
      "\n",
      "- **Autonomous Vehicles:** Self-driving cars that navigate roads, respond to traffic conditions, and make real-time decisions to ensure safe transportation.\n",
      "  \n",
      "- **Robotics:** Robots in manufacturing, healthcare, or service industries that perform tasks autonomously, such as assembly, surgery, or customer assistance.\n",
      "\n",
      "- **Virtual Assistants:** Advanced personal assistants like AI-driven chatbots that manage schedules, perform tasks, and interact with users proactively.\n",
      "\n",
      "- **Autonomous Trading Systems:** AI systems in finance that execute trades based on market analysis and predefined investment strategies without human intervention.\n",
      "\n",
      "- **Smart Homes:** Systems that automatically adjust lighting, temperature, security, and other home functions based on occupant behavior and preferences.\n",
      "\n",
      "### Benefits of Agentic AI\n",
      "\n",
      "- **Efficiency:** Automates repetitive or complex tasks, freeing humans to focus on more strategic activities.\n",
      "  \n",
      "- **Consistency:** Reduces human error by performing tasks with high precision and reliability.\n",
      "\n",
      "- **Scalability:** Can handle large volumes of data and processes that would be challenging for humans to manage effectively.\n",
      "\n",
      "- **Adaptability:** Learns and evolves with changing conditions, enhancing its performance over time.\n",
      "\n",
      "### Challenges and Considerations\n",
      "\n",
      "- **Ethics and Accountability:** Determining responsibility for the actions of autonomous agents, especially in critical applications like healthcare or transportation.\n",
      "\n",
      "- **Safety and Security:** Ensuring that agentic AI systems operate safely and are protected against malicious attacks or unintended behaviors.\n",
      "\n",
      "- **Transparency:** Making the decision-making processes of AI understandable to users and stakeholders to build trust and facilitate oversight.\n",
      "\n",
      "- **Control and Alignment:** Aligning the goals and behaviors of AI agents with human values and intentions to prevent adverse outcomes.\n",
      "\n",
      "### Future Outlook\n",
      "\n",
      "Agentic AI continues to advance, driven by improvements in machine learning, data processing, and computational power. As these systems become more sophisticated, they hold the potential to revolutionize various industries by enabling more intelligent, responsive, and efficient operations. However, it also necessitates ongoing dialogue and collaboration among technologists, policymakers, ethicists, and the public to address the accompanying ethical, social, and legal challenges.\n",
      "\n",
      "---\n",
      "\n",
      "In summary, **Agentic AI** represents a paradigm of artificial intelligence that emphasizes autonomy and proactive behavior, enabling systems to act as independent agents capable of achieving defined objectives through perception, decision-making, and action.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8357dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user is Hemanth. They started by saying hi and giving their name. I should respond politely.\\n\\nFirst, greet them back. Maybe say \"Hi Hemanth!\" to acknowledge their name. Keep it friendly.\\n\\nAsk how they\\'re doing. \"How are you today?\" is a common and polite question.\\n\\nOffer help since they might need assistance. \"Is there anything I can help you with?\" shows willingness to assist.\\n\\nMake sure the tone is warm and approachable. Avoid any technical jargon.\\n\\nCheck for any cultural nuances. Since the name Hemanth is common in some South Asian countries, maybe keep the language simple and universal.\\n\\nDon\\'t overcomplicate the response. Keep it short and natural.\\n\\nWait, the user\\'s message is just \"Hi My name is Hemanth\". Maybe they are starting a conversation, so a friendly reply is needed.\\n\\nAlso, ensure that the response is in the same language as the user\\'s message. Here, the user wrote in English, so respond in English.\\n\\nAlright, putting it all together: \"Hi Hemanth! Nice to meet you. How are you today? Is there anything I can help you with?\"\\n\\nThat should cover all the points. Let me make sure there are no typos. Yep, looks good.\\n</think>\\n\\nHi Hemanth! Nice to meet you. How are you today? Is there anything I can help you with?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 289, 'prompt_tokens': 17, 'total_tokens': 306, 'completion_time': 0.674737965, 'prompt_time': 0.003404947, 'queue_time': 0.8394926829999999, 'total_time': 0.678142912}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_9faf42d81f', 'finish_reason': 'stop', 'logprobs': None}, id='run--04f1eaff-4ecb-4e14-9cee-d4cdf076483e-0', usage_metadata={'input_tokens': 17, 'output_tokens': 289, 'total_tokens': 306})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "model.invoke(\"Hi My name is Hemanth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e170b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d414adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000021B689C9D90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000021B689CA990>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d40b1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000021B689C9D90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000021B689CA990>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### chaining\n",
    "chain=prompt|model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a293571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI engineer, I can definitely tell you about Langsmith! \n",
      "\n",
      "Langsmith is an open-source project by the folks at Weights & Biases, focused on making it **easier to build and deploy machine learning (ML) applications, particularly those involving large language models (LLMs).** \n",
      "\n",
      "Here are some key things to know about Langsmith:\n",
      "\n",
      "**1. Streamlined LLM Development:**\n",
      "\n",
      "* **Simplified Prompt Engineering:** Langsmith provides a user-friendly interface and tools to experiment with and refine prompts for LLMs, making the process more efficient.\n",
      "* **Model Management:** It helps you easily manage different LLM models, switching between them, comparing results, and tracking their performance.\n",
      "* **Pipeline Building:** Langsmith enables you to create and chain together multiple LLM operations into custom pipelines, automating complex workflows.\n",
      "\n",
      "**2. Collaboration and Sharing:**\n",
      "\n",
      "* **Open-Source Nature:** Being open-source, Langsmith fosters community contribution and allows anyone to modify or extend its functionality.\n",
      "* **Collaborative Development:** It supports collaborative development environments, enabling teams to work together on LLM projects more effectively.\n",
      "\n",
      "**3. Integration and Deployment:**\n",
      "\n",
      "* **API-First Approach:** Langsmith exposes its capabilities through a well-documented API, making it easy to integrate with other tools and systems.\n",
      "* **Deployment Flexibility:** It supports deploying LLM applications in various environments, including cloud platforms and on-premise servers.\n",
      "\n",
      "**4. Focus on Efficiency:**\n",
      "\n",
      "* **Performance Optimization:** Langsmith aims to optimize LLM performance and reduce inference costs.\n",
      "* **Resource Management:** It helps manage LLM resource usage effectively, ensuring efficient utilization of hardware resources.\n",
      "\n",
      "**Langsmith is a powerful tool for anyone interested in exploring and building with LLMs. Its user-friendly interface, collaborative features, and focus on efficiency make it a valuable resource for both beginners and experienced developers.**\n",
      "\n",
      "\n",
      "Let me know if you have any more specific questions about Langsmith â€“ I'm happy to provide more details!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\":\"Can you tell me something about Langsmith\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6694a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's talk about Langsmith! \n",
      "\n",
      "**Langsmith** is an open-source, community-driven platform designed to streamline the process of building, evaluating, and deploying large language models (LLMs). It's a powerful toolset that empowers developers and researchers to work with LLMs more efficiently and effectively.\n",
      "\n",
      "**Here's a breakdown of its key features and benefits:**\n",
      "\n",
      "* **Simplified LLM Development:**\n",
      "\n",
      "Langsmith provides a user-friendly interface and pre-built components that simplify the complexities of LLM development. This makes it accessible to a wider range of users, including those without extensive machine learning expertise.\n",
      "\n",
      "* **Streamlined Training and Evaluation:** The platform offers tools for efficient training, fine-tuning, and evaluating LLMs. It integrates with popular deep learning frameworks like PyTorch and TensorFlow, allowing you to leverage existing infrastructure and expertise.\n",
      "\n",
      "* **Collaborative Ecosystem:** Langsmith fosters a collaborative environment where developers can share models, datasets, and best practices. This open-source nature promotes innovation and accelerates progress in the field of LLMs.\n",
      "\n",
      "* **Model Deployment and Management:** The platform assists in deploying trained LLMs to various environments, including cloud platforms and local servers. It also provides tools for monitoring and managing deployed models, ensuring their optimal performance.\n",
      "\n",
      "* **Focus on Ethical Considerations:** Langsmith emphasizes responsible AI development by incorporating guidelines and best practices for mitigating bias, ensuring fairness, and promoting transparency in LLM development.\n",
      "\n",
      "**Who Benefits from Langsmith?**\n",
      "\n",
      "* **Researchers:**\n",
      "\n",
      "Langsmith empowers researchers to experiment with new LLM architectures, explore different training techniques, and accelerate their research endeavors.\n",
      "* **Developers:**\n",
      "\n",
      "Developers can leverage Langsmith to build LLM-powered applications, integrate LLMs into existing systems, and create innovative solutions across various domains.\n",
      "* **Data Scientists:** Langsmith provides data scientists with tools to analyze and understand the behavior of LLMs, contributing to the advancement of natural language processing research.\n",
      "\n",
      "**In Essence:**\n",
      "\n",
      "Langsmith is a comprehensive platform that democratizes access to LLM technology, making it easier for individuals and organizations to explore, develop, and deploy powerful AI solutions.\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about Langsmith or LLMs in general. I'm here to help!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "chain=prompt|model|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0221a0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66da8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fe079e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52a5b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Langsmith', 'description': 'Langsmith is an open-source platform developed by the LangChain team for building and deploying AI applications.', 'features': ['Modular and composable components for building complex AI applications', 'Support for various AI models, including open-source and proprietary options', 'Tools for data management, including data loading, cleaning, and processing', 'Environment management for running and deploying AI applications', 'User-friendly interface and APIs for easy integration and development', 'Community-driven development with active support and contributions'], 'use cases': ['Chatbots and conversational AI', 'Text summarization and generation', 'Code generation and assistance', 'Data analysis and insights', 'Personalized learning and education'], 'website': 'https://github.com/langchain-ai/langsmith'}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ee96082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Assisgnment ---Chatprompttemplate\n",
    "\n",
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed7d7e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'Langsmith is an open-source platform developed by AI21 Labs that simplifies the process of building and deploying AI-powered applications. \\n\\n  **Key Features:**\\n\\n  * **No-Code Interface:**  Langsmith offers a user-friendly, visual interface that allows users to create and train AI models without writing code.\\n  * **Modular Design:**  It provides a modular architecture that enables developers to easily integrate different components, such as text generation, summarization, and question answering, into their applications.\\n  * **Fine-Tuning Capabilities:** Users can fine-tune pre-trained language models on their own datasets to create specialized AI assistants tailored to specific tasks.\\n  * **API Access:** Langsmith provides an API that allows developers to access its functionalities programmatically for more advanced integrations.\\n\\n  **Benefits:**\\n\\n  * **Accessibility:**  Makes AI development accessible to a wider range of users, including those without coding expertise.\\n  * **Efficiency:**  Streamlines the development process, reducing time and effort required to build AI applications.\\n  * **Customization:**  Allows users to create AI solutions that are tailored to their specific needs and use cases.\\n\\n  **Use Cases:**\\n\\n  * **Chatbots and Virtual Assistants:** Create conversational AI agents for customer service, education, or entertainment.\\n  * **Content Creation:** Generate articles, stories, summaries, and other types of written content.\\n  * **Data Analysis and Insights:**  Extract insights and patterns from text data.\\n  * **Code Generation:** Assist developers in writing and debugging code.\\n\\n  **Overall, Langsmith is a powerful and versatile platform that empowers individuals and organizations to leverage the capabilities of artificial intelligence for a variety of applications.'}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50822936",
   "metadata": {},
   "source": [
    "### Assigments: https://python.langchain.com/docs/how_to/#prompt-templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c1c1802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "output_parser=XMLOutputParser()\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca6e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "940f704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```xml\\n<response>\\n  <name>Langsmith</name>\\n  <description>Langsmith is an open-source platform for developing and deploying large language models (LLMs). It provides a modular and customizable framework for training, evaluating, and serving LLMs.</description>\\n  <features>\\n    <feature>Modular Design</feature>\\n    <feature>Customizable Training</feature>\\n    <feature>Model Evaluation Tools</feature>\\n    <feature>Deployment Flexibility</feature>\\n  </features>\\n  <website>https://github.com/langsmith-ai/langsmith</website>\\n</response>\\n``` \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 142, 'prompt_tokens': 195, 'total_tokens': 337, 'completion_time': 0.258181818, 'prompt_time': 0.007797309, 'queue_time': 0.24386954400000002, 'total_time': 0.265979127}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--0f1242af-0bfe-4726-a1aa-e4efdeee00b4-0' usage_metadata={'input_tokens': 195, 'output_tokens': 142, 'total_tokens': 337}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1eec50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<response>\\n<answer>LangChain is a framework for developing applications powered by large language models (LLMs). It provides tools and components for connecting LLMs with other data sources, managing their memory, and building complex conversational flows.</answer>\\n</response>\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 39, 'total_tokens': 96, 'completion_time': 0.103636364, 'prompt_time': 0.002385457, 'queue_time': 0.243690303, 'total_time': 0.106021821}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--4f5f89cd-658a-467e-be5f-301c586b8f69-0' usage_metadata={'input_tokens': 39, 'output_tokens': 57, 'total_tokens': 96}\n"
     ]
    }
   ],
   "source": [
    "##output parser\n",
    "#from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "# XML Output Parser\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "# Prompt that instructs the model to return XML\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Build the chain\n",
    "chain = prompt | model\n",
    "\n",
    "# Run the chain\n",
    "#response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "raw_output =chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "# Print result\n",
    "print(raw_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab7431f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'Because it was two tired!'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With Pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36e1dcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why couldn't the bicycle stand up by itself? Because it was two tired!\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Pydantic\n",
    "joke_query = \"Tell me a joke .\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f2ec0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<movie>Big</movie>\n",
      "<movie>A League of Their Own</movie>\n",
      "<movie>Forrest Gump</movie>\n",
      "<movie>Apollo 13</movie>\n",
      "<movie>Saving Private Ryan</movie>\n",
      "<movie>The Green Mile</movie>\n",
      "<movie>Cast Away</movie>\n",
      "<movie>Catch Me If You Can</movie>\n",
      "<movie>The Da Vinci Code</movie>\n",
      "<movie>Bridge of Spies</movie>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "\n",
    "output = model.invoke(\n",
    "    f\"\"\"{actor_query}\n",
    "Please enclose the movies in <movie></movie> tags\"\"\"\n",
    ")\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c90caccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = YamlOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfed2d4",
   "metadata": {},
   "source": [
    "### Assisgment:\n",
    "Create a simple assistant that uses any LLM and should be pydantic, when we ask about any product it should give you two information product Name, product details tentative price in USD (integer). use chat Prompt Template.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2999f98",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
